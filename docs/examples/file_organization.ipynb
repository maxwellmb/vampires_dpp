{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Organization\n",
    "\n",
    "This notebook shows two ways of using `vampires_dpp` to help organize your data for processing. This notebook can be downloaded as **{nb-download}`file_organization.ipynb`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from zenodo_get import zenodo_get\n",
    "\n",
    "datadir = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Title: VAMPIRES DPP Example Files\n",
      "Keywords: \n",
      "Publication date: 2022-11-24\n",
      "DOI: 10.5281/zenodo.7359198\n",
      "Total size: 231.0 MB\n",
      "\n",
      "Link: https://zenodo.org/api/files/cc9ed3d2-b13e-4d43-a50c-db8c33f84c42/ABAur_01_20190320_750-50_EmptySlot_00_cam1_hdr_calib_FLC1.fits   size: 100.0 MB\n",
      "ABAur_01_20190320_750-50_EmptySlot_00_cam1_hdr_calib_FLC1.fits is already downloaded correctly.\n",
      "\n",
      "Link: https://zenodo.org/api/files/cc9ed3d2-b13e-4d43-a50c-db8c33f84c42/ABAur_02__RS___20220224_750-50_LyotStop_00_cam1_fix_calib_FLC1.fits   size: 31.0 MB\n",
      "ABAur_02__RS___20220224_750-50_LyotStop_00_cam1_fix_calib_FLC1.fits is already downloaded correctly.\n",
      "\n",
      "Link: https://zenodo.org/api/files/cc9ed3d2-b13e-4d43-a50c-db8c33f84c42/bench_CLC-3_750-50_LyotStop_00_cam1_calib.fits   size: 100.0 MB\n",
      "bench_CLC-3_750-50_LyotStop_00_cam1_calib.fits is already downloaded correctly.\n",
      "All files have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "# download example data\n",
    "zenodo_get([\"10.5281/zenodo.7359198\", \"-o\", datadir.absolute()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Tables\n",
    "\n",
    "To help organize our data, which is often in a single directory with STARS frame IDs that provide no useful identification, we can sort, filter, and save all of the data from the FITS headers. We have an automated utility which scrapes all the FITS headers and stores the data into a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to load your input data into a table and save that to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from vampires_dpp.headers import observation_table\n",
    "\n",
    "datadir = Path(\"data\")\n",
    "filelist = datadir.glob(\"VMPA*.fits\")\n",
    "table = observation_table(filelist) # sorts by DATE by default\n",
    "table.to_csv(datadir / \"hd32297_20220225_headers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will load a table from observations on 2022/02/25 of HD 32297 in polarimetric imaging mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'path', 'SIMPLE', 'BITPIX', 'NAXIS', 'NAXIS1', 'NAXIS2',\n",
       "       'NAXIS3', 'EXTEND', 'BSCALE',\n",
       "       ...\n",
       "       'D_LOOP', 'D_LTTG', 'D_PSUBG', 'D_STTG', 'D_TTCMTX', 'D_TTGAIN',\n",
       "       'D_WTTG', 'DATE', 'U_FLCSTT', 'COMMENT'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_csv(datadir / \"hd32297_20220225_headers.csv\")\n",
    "table.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Files\n",
    "\n",
    "We need to separate out the calibration data from the science data, including the reference stars. From this observation, our targets were as follows\n",
    "\n",
    "**Science Targets**\n",
    "- HD 32297\n",
    "\n",
    "**Reference Targets**\n",
    "- HD 42352 (Polarized Standard)\n",
    "- HD 87423 (Unpolarized Standard)\n",
    "- HD 32909 (PSF Reference)\n",
    "\n",
    "We will use pandas' [`query`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html) functionality to easily sort our files by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science files: 650\n",
      "Pol. standard files: 30\n",
      "Unpol. standard files: 46\n",
      "PSF ref. files: 36\n"
     ]
    }
   ],
   "source": [
    "sci_table = table.query(\"OBJECT == 'HD32297'\")\n",
    "pol_table = table.query(\"OBJECT == 'HD42352'\")\n",
    "unpol_table = table.query(\"OBJECT == 'HD87423'\")\n",
    "psfref_table = table.query(\"OBJECT == 'HD32909'\")\n",
    "\n",
    "print(f\"Science files: {len(sci_table)}\")\n",
    "print(f\"Pol. standard files: {len(pol_table)}\")\n",
    "print(f\"Unpol. standard files: {len(unpol_table)}\")\n",
    "print(f\"PSF ref. files: {len(psfref_table)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration files\n",
    "\n",
    "Depending on when you observed with VAMPIRES and who your suppert astronomers were, your calibration files (typically just dark frames) can be found a few ways.\n",
    "\n",
    "For example, if your darks were archived in STARS and were taken with the mirror in, you can use the `U_MASK` value to filter the table\n",
    "\n",
    "```python\n",
    "dark_table = table.query(\"U_MASK == 'Mirror'\")\n",
    "```\n",
    "\n",
    "If the darks were just taken during slews, you can try filtering `U_OGFNAM` (the filename as saved to the VAMPIRES computer, usually much more descriptive) for \"skies\"\n",
    "\n",
    "```python\n",
    "dark_table = table.loc[table[\"U_OGFNAM\"].str.contains(\"skies\")]\n",
    "```\n",
    "\n",
    "In some cases, you may be given the dark files directly if they were not saved in STARS. In that case, you should just store them in your data directory and add the filenames directly to your pipeline configuration.\n",
    "\n",
    "For our observations, we took dark frames during slews, so we'll use the \"skies\" method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark frames (skies): 26\n"
     ]
    }
   ],
   "source": [
    "dark_table = table.loc[table[\"U_OGFNAM\"].str.contains(\"skies\")]\n",
    "\n",
    "print(f\"Dark frames (skies): {len(dark_table)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we don't need all of these cubes to make our calibration files- in general you shouldn't need more than a few hundred or thousand frames in total (typically one data cube). It is important, however, to match the exposure time and EM gain of our other images!\n",
    "\n",
    "The `find_dark_settings` function will automatically sort through the files and find the unique combinations of exposure times and EM gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science: 0.5 s / EM 300\n",
      "Science: 0.25 s / EM 300\n",
      "Pol. standard: 0.25 s / EM 10\n",
      "Pol. standard: 0.25 s / EM 300\n",
      "Unpol. standard: 0.5 s / EM 0\n",
      "Unpol. standard: 0.5 s / EM 280\n",
      "PSF ref.: 0.5 s / EM 300\n"
     ]
    }
   ],
   "source": [
    "from vampires_dpp.util import find_dark_settings\n",
    "\n",
    "print(\"\\n\".join(f\"Science: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(sci_table.path)))\n",
    "print(\"\\n\".join(f\"Pol. standard: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(pol_table.path)))\n",
    "print(\"\\n\".join(f\"Unpol. standard: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(unpol_table.path)))\n",
    "print(\"\\n\".join(f\"PSF ref.: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(psfref_table.path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see from the EM gain switches that some of the standard stars were taken with the coronagraph in (high gain) and with the coronagraph out (low gain). We could use this information to further filter the tables with `query`, but for now we're only going to focus on the main science observations, which are those with exposure time of 0.5 seconds and 300 EM gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_table = sci_table.query(\"EXPTIME == 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5]), array([300.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dark_table[\"EXPTIME\"].unique(), dark_table[\"U_EMGAIN\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our sky frames only cover the 0.5 second, 300 EM gain files. In order to fully calibrate our reference data, we would need to reach out to the SCExAO team to record some darks for the other exposure times and gains.\n",
    "\n",
    "From the skies, we only need one cube per camera, so we'll select the first two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam 1 dark: /Volumes/mlucas SSD1/2022/20220225/VMPA00022727.fits\n",
      "Cam 2 dark: /Volumes/mlucas SSD1/2022/20220225/VMPA00022723.fits\n"
     ]
    }
   ],
   "source": [
    "cam1_dark = dark_table.query(\"U_CAMERA == 1\").iloc[0]\n",
    "cam2_dark = dark_table.query(\"U_CAMERA == 2\").iloc[0]\n",
    "print(f\"Cam 1 dark: {cam1_dark.path}\")\n",
    "print(f\"Cam 2 dark: {cam2_dark.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for processing\n",
    "\n",
    "Now that we have our file lists, we can prepare them for processing using the `vampires_dpp` pipeline. We'll show you a few ways for organizing your data so you can chose one that suits your needs and tweak to your liking!\n",
    "\n",
    "### 1. File lists\n",
    "\n",
    "We can take our dataframes and save the paths of our selected files to simple text files, which can be input directly into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_files = datadir / \"hd32297_files.txt\"\n",
    "with open(sci_files, \"w\") as fh:\n",
    "    fh.writelines(\"\\n\".join(sci_table[\"path\"]))\n",
    "\n",
    "dark_files = datadir / \"dark_files.txt\"\n",
    "with open(dark_files, \"w\") as fh:\n",
    "    fh.writelines(\"\\n\".join(c.path for c in (cam1_dark, cam2_dark)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022083.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022084.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022085.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022086.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022087.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022088.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022089.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022090.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022091.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022092.fits\n"
     ]
    }
   ],
   "source": [
    "!head data/hd32297_files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022727.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022723.fits"
     ]
    }
   ],
   "source": [
    "!head data/dark_files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vampires_dpp.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_str(\"\"\"\n",
    "version = \"0.2.0\"\n",
    "name=\"HD32297_20220225\"\n",
    "directory=\"data\"\n",
    "output_directory=\"data/processed\"\n",
    "filenames=\"data/hd32297_files.txt\"\n",
    "\n",
    "[calibration]\n",
    "output_directory=\"calibrated\"\n",
    "\n",
    "[calibration.darks]\n",
    "filenames=\"data/dark_files.txt\"\n",
    "\n",
    "[registration]\n",
    "output_directory=\"registered\"\n",
    "\n",
    "[collapsing]\n",
    "output_directory=\"collapsed\"\n",
    "\n",
    "[derotate]\n",
    "output_directory=\"derotated\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sub-directories\n",
    "\n",
    "If you prefer to copy your data into sub-directories, you can do that straight from our tables and using Python's built-in file management tools. Here we will use symlinks to save storage space, but you could use `shutil.copyfile` if you wanted to make hard copies instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "sci_dir = datadir / \"hd32297_science\"\n",
    "sci_dir.mkdir(parents=True, exist_ok=True)\n",
    "for filename in sci_table[\"path\"]:\n",
    "    path = Path(filename)\n",
    "    outpath = sci_dir / path.name\n",
    "    outpath.symlink_to(path)\n",
    "\n",
    "\n",
    "dark_dir = datadir / \"darks\"\n",
    "dark_dir.mkdir(parents=True, exist_ok=True)\n",
    "for filename in (cam1_dark.path, cam2_dark.path):\n",
    "    path = Path(filename)\n",
    "    outpath = dark_dir / path.name\n",
    "    outpath.symlink_to(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_str(\"\"\"\n",
    "version = \"0.2.0\"\n",
    "name=\"HD32297_20220225\"\n",
    "directory=\"data\"\n",
    "output_directory=\"data/processed\"\n",
    "filenames=\"hd32297_science/VMPA*.fits\"\n",
    "\n",
    "[calibration]\n",
    "output_directory=\"calibrated\"\n",
    "\n",
    "[calibration.darks]\n",
    "filenames=\"darks/VMPA*.fits\"\n",
    "\n",
    "[registration]\n",
    "output_directory=\"registered\"\n",
    "\n",
    "[collapsing]\n",
    "output_directory=\"collapsed\"\n",
    "\n",
    "[derotate]\n",
    "output_directory=\"derotated\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Direct configuration\n",
    "\n",
    "The last way we could do this is by directly creating a configuration dictionary, bypassing the TOML configuration altogether.\n",
    "\n",
    "```{admonition} Advanced Usage\n",
    ":class: caution\n",
    "\n",
    "Despite this methods ability to work in pure Python, the heavily-nested structure can be easy to screw up, leading to silent failures like missing dark subtraction.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline({\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"name\": \"HD32297_20220225\",\n",
    "    \"directory\": datadir,\n",
    "    \"output_directory\": datadir / \"processed\",\n",
    "    \"filenames\": sci_table[\"path\"],\n",
    "    \"calibration\": {\n",
    "        \"output_directory\": \"calibrated\",\n",
    "        \"darks\": {\"filenames\": dark_table[\"path\"]}\n",
    "    },\n",
    "    \"registration\": {\"output_directory\": \"registered\"},\n",
    "    \"collapsing\": {\"output_directory\": \"collapsed\"},\n",
    "    \"derotate\": {\"output_directory\": \"derotated\"},\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07c794eeb24af7d903d5afc8ab13421c96f6db73efe7b96341c3358833b50799"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
