{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Organization\n",
    "\n",
    "This notebook shows two ways of using `vampires_dpp` to help organize your data for processing. This notebook can be downloaded as **{nb-download}`file_organization.ipynb`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from zenodo_get import zenodo_get\n",
    "\n",
    "datadir = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Title: VAMPIRES DPP Example Files\n",
      "Keywords: \n",
      "Publication date: 2022-11-24\n",
      "DOI: 10.5281/zenodo.7359198\n",
      "Total size: 231.8 MB\n",
      "\n",
      "Link: https://zenodo.org/api/files/a16d7d26-dcff-49c8-89f4-08e5c46c99ac/ABAur_01_20190320_750-50_EmptySlot_00_cam1_hdr_calib_FLC1.fits   size: 100.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABAur_01_20190320_750-50_EmptySlot_00_cam1_hdr_calib_FLC1.fits is already downloaded correctly.\n",
      "\n",
      "Link: https://zenodo.org/api/files/a16d7d26-dcff-49c8-89f4-08e5c46c99ac/ABAur_02__RS___20220224_750-50_LyotStop_00_cam1_fix_calib_FLC1.fits   size: 31.0 MB\n",
      "ABAur_02__RS___20220224_750-50_LyotStop_00_cam1_fix_calib_FLC1.fits is already downloaded correctly.\n",
      "\n",
      "Link: https://zenodo.org/api/files/a16d7d26-dcff-49c8-89f4-08e5c46c99ac/bench_CLC-3_750-50_LyotStop_00_cam1_calib.fits   size: 100.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bench_CLC-3_750-50_LyotStop_00_cam1_calib.fits is already downloaded correctly.\n",
      "\n",
      "Link: https://zenodo.org/api/files/a16d7d26-dcff-49c8-89f4-08e5c46c99ac/hd32297_20220225_headers.csv   size: 0.8 MB\n",
      "hd32297_20220225_headers.csv is already downloaded correctly.\n",
      "All files have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "# download example data\n",
    "zenodo_get([\"10.5281/zenodo.7359198\", \"-o\", datadir.absolute()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Tables\n",
    "\n",
    "To help organize our data, which is often in a single directory with STARS frame IDs that provide no useful identification, we can sort, filter, and save all of the data from the FITS headers. We have an automated utility which scrapes all the FITS headers and stores the data into a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to load your input data into a table and save that to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from vampires_dpp.headers import observation_table\n",
    "\n",
    "datadir = Path(\"data\")\n",
    "filelist = datadir.glob(\"VMPA*.fits\")\n",
    "table = observation_table(filelist) # sorts by DATE by default\n",
    "table.to_csv(datadir / \"hd32297_20220225_headers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will load a table from observations on 2022/02/25 of HD 32297 in polarimetric imaging mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'path', 'SIMPLE', 'BITPIX', 'NAXIS', 'NAXIS1', 'NAXIS2',\n",
       "       'NAXIS3', 'EXTEND', 'BSCALE',\n",
       "       ...\n",
       "       'D_LOOP', 'D_LTTG', 'D_PSUBG', 'D_STTG', 'D_TTCMTX', 'D_TTGAIN',\n",
       "       'D_WTTG', 'DATE', 'U_FLCSTT', 'COMMENT'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_csv(datadir / \"hd32297_20220225_headers.csv\")\n",
    "table.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Files\n",
    "\n",
    "We need to separate out the calibration data from the science data, including the reference stars. From this observation, our targets were as follows\n",
    "\n",
    "**Science Targets**\n",
    "- HD 32297\n",
    "\n",
    "**Reference Targets**\n",
    "- HD 42352 (Polarized Standard)\n",
    "- HD 87423 (Unpolarized Standard)\n",
    "- HD 32909 (PSF Reference)\n",
    "\n",
    "We will use pandas' [`query`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html) functionality to easily sort our files by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science files: 650\n",
      "Pol. standard files: 30\n",
      "Unpol. standard files: 46\n",
      "PSF ref. files: 36\n"
     ]
    }
   ],
   "source": [
    "sci_table = table.query(\"OBJECT == 'HD32297'\")\n",
    "pol_table = table.query(\"OBJECT == 'HD42352'\")\n",
    "unpol_table = table.query(\"OBJECT == 'HD87423'\")\n",
    "psfref_table = table.query(\"OBJECT == 'HD32909'\")\n",
    "\n",
    "print(f\"Science files: {len(sci_table)}\")\n",
    "print(f\"Pol. standard files: {len(pol_table)}\")\n",
    "print(f\"Unpol. standard files: {len(unpol_table)}\")\n",
    "print(f\"PSF ref. files: {len(psfref_table)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration files\n",
    "\n",
    "Depending on when you observed with VAMPIRES and who your suppert astronomers were, your calibration files (typically just dark frames) can be found a few ways.\n",
    "\n",
    "For example, if your darks were archived in STARS and were taken with the mirror in, you can use the `U_MASK` value to filter the table\n",
    "\n",
    "```python\n",
    "dark_table = table.query(\"U_MASK == 'Mirror'\")\n",
    "```\n",
    "\n",
    "If the darks were just taken during slews, you can try filtering `U_OGFNAM` (the filename as saved to the VAMPIRES computer, usually much more descriptive) for \"skies\"\n",
    "\n",
    "```python\n",
    "dark_table = table.loc[table[\"U_OGFNAM\"].str.contains(\"skies\")]\n",
    "```\n",
    "\n",
    "In some cases, you may be given the dark files directly if they were not saved in STARS. In that case, you should just store them in your data directory and add the filenames directly to your pipeline configuration.\n",
    "\n",
    "For our observations, we took dark frames during slews, so we'll use the \"skies\" method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark frames (skies): 26\n"
     ]
    }
   ],
   "source": [
    "dark_table = table.loc[table[\"U_OGFNAM\"].str.contains(\"skies\")]\n",
    "\n",
    "print(f\"Dark frames (skies): {len(dark_table)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we don't need all of these cubes to make our calibration files- in general you shouldn't need more than a few hundred or thousand frames in total (typically one data cube). It is important, however, to match the exposure time and EM gain of our other images!\n",
    "\n",
    "The `find_dark_settings` function will automatically sort through the files and find the unique combinations of exposure times and EM gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/mlucas SSD1/2022/20220225/VMPA00022079.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvampires_dpp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_dark_settings\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScience: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s / EM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t, e \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfind_dark_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msci_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPol. standard: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s / EM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t, e \u001b[38;5;129;01min\u001b[39;00m find_dark_settings(pol_table\u001b[38;5;241m.\u001b[39mpath)))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnpol. standard: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s / EM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t, e \u001b[38;5;129;01min\u001b[39;00m find_dark_settings(unpol_table\u001b[38;5;241m.\u001b[39mpath)))\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/vampires_dpp/util.py:62\u001b[0m, in \u001b[0;36mfind_dark_settings\u001b[0;34m(filelist)\u001b[0m\n\u001b[1;32m     60\u001b[0m exp_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filelist:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hdus:\n\u001b[1;32m     63\u001b[0m         hdr \u001b[38;5;241m=\u001b[39m hdus[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mheader\n\u001b[1;32m     64\u001b[0m         texp \u001b[38;5;241m=\u001b[39m hdr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXPTIME\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# exposure time in microseconds\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py:175\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py:410\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\u001b[38;5;28mcls\u001b[39m, fileobj, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m              save_backup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lazy_load_hdus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m              ignore_missing_simple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py:1062\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1061\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/astropy/io/fits/file.py:170\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_fileobj(fileobj, mode, overwrite)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filelike(fileobj, mode, overwrite)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/astropy/io/fits/file.py:562\u001b[0m, in \u001b[0;36m_File._open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    559\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_read_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, magic, mode, ext\u001b[38;5;241m=\u001b[39mext):\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIO_FITS_MODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_on_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/mlucas SSD1/2022/20220225/VMPA00022079.fits'"
     ]
    }
   ],
   "source": [
    "from vampires_dpp.util import find_dark_settings\n",
    "\n",
    "print(\"\\n\".join(f\"Science: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(sci_table.path)))\n",
    "print(\"\\n\".join(f\"Pol. standard: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(pol_table.path)))\n",
    "print(\"\\n\".join(f\"Unpol. standard: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(unpol_table.path)))\n",
    "print(\"\\n\".join(f\"PSF ref.: {t} s / EM {e:.0f}\" for t, e in find_dark_settings(psfref_table.path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see from the EM gain switches that some of the standard stars were taken with the coronagraph in (high gain) and with the coronagraph out (low gain). We could use this information to further filter the tables with `query`, but for now we're only going to focus on the main science observations, which are those with exposure time of 0.5 seconds and 300 EM gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_table = sci_table.query(\"EXPTIME == 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5]), array([300.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dark_table[\"EXPTIME\"].unique(), dark_table[\"U_EMGAIN\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our sky frames only cover the 0.5 second, 300 EM gain files. In order to fully calibrate our reference data, we would need to reach out to the SCExAO team to record some darks for the other exposure times and gains.\n",
    "\n",
    "From the skies, we only need one cube per camera, so we'll select the first two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam 1 dark: /Volumes/mlucas SSD1/2022/20220225/VMPA00022727.fits\n",
      "Cam 2 dark: /Volumes/mlucas SSD1/2022/20220225/VMPA00022723.fits\n"
     ]
    }
   ],
   "source": [
    "cam1_dark = dark_table.query(\"U_CAMERA == 1\").iloc[0]\n",
    "cam2_dark = dark_table.query(\"U_CAMERA == 2\").iloc[0]\n",
    "print(f\"Cam 1 dark: {cam1_dark.path}\")\n",
    "print(f\"Cam 2 dark: {cam2_dark.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for processing\n",
    "\n",
    "Now that we have our file lists, we can prepare them for processing using the `vampires_dpp` pipeline. We'll show you a few ways for organizing your data so you can chose one that suits your needs and tweak to your liking!\n",
    "\n",
    "### 1. File lists\n",
    "\n",
    "We can take our dataframes and save the paths of our selected files to simple text files, which can be input directly into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_files = datadir / \"hd32297_files.txt\"\n",
    "with open(sci_files, \"w\") as fh:\n",
    "    fh.writelines(\"\\n\".join(sci_table[\"path\"]))\n",
    "\n",
    "dark_files = datadir / \"dark_files.txt\"\n",
    "with open(dark_files, \"w\") as fh:\n",
    "    fh.writelines(\"\\n\".join(c.path for c in (cam1_dark, cam2_dark)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022083.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022084.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022085.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022086.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022087.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022088.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022089.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022090.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022091.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022092.fits\n"
     ]
    }
   ],
   "source": [
    "!head data/hd32297_files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022727.fits\n",
      "/Volumes/mlucas SSD1/2022/20220225/VMPA00022723.fits"
     ]
    }
   ],
   "source": [
    "!head data/dark_files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vampires_dpp.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_str(\"\"\"\n",
    "version = \"0.2.0\"\n",
    "name=\"HD32297_20220225\"\n",
    "directory=\"data\"\n",
    "output_directory=\"data/processed\"\n",
    "filenames=\"data/hd32297_files.txt\"\n",
    "\n",
    "[calibration]\n",
    "output_directory=\"calibrated\"\n",
    "\n",
    "[calibration.darks]\n",
    "filenames=\"data/dark_files.txt\"\n",
    "\n",
    "[registration]\n",
    "output_directory=\"registered\"\n",
    "\n",
    "[collapsing]\n",
    "output_directory=\"collapsed\"\n",
    "\n",
    "[derotate]\n",
    "output_directory=\"derotated\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sub-directories\n",
    "\n",
    "If you prefer to copy your data into sub-directories, you can do that straight from our tables and using Python's built-in file management tools. Here we will use symlinks to save storage space, but you could use `shutil.copyfile` if you wanted to make hard copies instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "sci_dir = datadir / \"hd32297_science\"\n",
    "sci_dir.mkdir(parents=True, exist_ok=True)\n",
    "for filename in sci_table[\"path\"]:\n",
    "    path = Path(filename)\n",
    "    outpath = sci_dir / path.name\n",
    "    outpath.symlink_to(path)\n",
    "\n",
    "\n",
    "dark_dir = datadir / \"darks\"\n",
    "dark_dir.mkdir(parents=True, exist_ok=True)\n",
    "for filename in (cam1_dark.path, cam2_dark.path):\n",
    "    path = Path(filename)\n",
    "    outpath = dark_dir / path.name\n",
    "    outpath.symlink_to(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_str(\"\"\"\n",
    "version = \"0.2.0\"\n",
    "name=\"HD32297_20220225\"\n",
    "directory=\"data\"\n",
    "output_directory=\"data/processed\"\n",
    "filenames=\"hd32297_science/VMPA*.fits\"\n",
    "\n",
    "[calibration]\n",
    "output_directory=\"calibrated\"\n",
    "\n",
    "[calibration.darks]\n",
    "filenames=\"darks/VMPA*.fits\"\n",
    "\n",
    "[registration]\n",
    "output_directory=\"registered\"\n",
    "\n",
    "[collapsing]\n",
    "output_directory=\"collapsed\"\n",
    "\n",
    "[derotate]\n",
    "output_directory=\"derotated\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Direct configuration\n",
    "\n",
    "The last way we could do this is by directly creating a configuration dictionary, bypassing the TOML configuration altogether.\n",
    "\n",
    "```{admonition} Advanced Usage\n",
    ":class: caution\n",
    "\n",
    "Despite this methods ability to work in pure Python, the heavily-nested structure can be easy to screw up, leading to silent failures like missing dark subtraction.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline({\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"name\": \"HD32297_20220225\",\n",
    "    \"directory\": datadir,\n",
    "    \"output_directory\": datadir / \"processed\",\n",
    "    \"filenames\": sci_table[\"path\"],\n",
    "    \"calibration\": {\n",
    "        \"output_directory\": \"calibrated\",\n",
    "        \"darks\": {\"filenames\": dark_table[\"path\"]}\n",
    "    },\n",
    "    \"registration\": {\"output_directory\": \"registered\"},\n",
    "    \"collapsing\": {\"output_directory\": \"collapsed\"},\n",
    "    \"derotate\": {\"output_directory\": \"derotated\"},\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "07c794eeb24af7d903d5afc8ab13421c96f6db73efe7b96341c3358833b50799"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}